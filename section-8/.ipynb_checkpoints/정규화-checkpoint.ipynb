{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bdfabfd9-d0ef-40c7-9c0e-1bb119013283",
   "metadata": {},
   "source": [
    "# 텍스트 정규화\n",
    "\n",
    "- https://www.nltk.org/\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29faa419-298f-4025-843e-22497a31270f",
   "metadata": {},
   "source": [
    "## Text Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b0b177-57fc-47c8-b301-3a4c2dd4552f",
   "metadata": {},
   "source": [
    "### 문장 토큰화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "201db019-6c1f-4f4c-abb5-39b92c917708",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b823d4ff-283f-4bb8-8686-6dc055e74dd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cc53eeae-be06-4177-b2d2-3c3f4310d3f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'> 3\n",
      "['The Matrix is everywhere its all around us, here even in this room.', 'You can see it out your window or on your television.', 'You feel it when you go to work, or go to church or pay your texes.']\n"
     ]
    }
   ],
   "source": [
    "text_sample = 'The Matrix is everywhere its all around us, here even in this room.\\\n",
    "               You can see it out your window or on your television.\\\n",
    "               You feel it when you go to work, or go to church or pay your texes.'\n",
    "sentences = sent_tokenize(text=text_sample)\n",
    "print(type(sentences), len(sentences))\n",
    "print(sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe7413db-8bcf-4d2d-a6af-77b35d695ab2",
   "metadata": {},
   "source": [
    "### 단어 토큰화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "013ff6a4-8491-4248-9e6b-4495fbb5c5ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7f72a3fe-4904-4fcd-a5ff-4e1d6bd8088b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'> 15\n",
      "['The', 'Matrix', 'is', 'everywhere', 'its', 'all', 'around', 'us', ',', 'here', 'even', 'in', 'this', 'room', '.']\n"
     ]
    }
   ],
   "source": [
    "sentence = \"The Matrix is everywhere its all around us, here even in this room.\"\n",
    "words = word_tokenize(sentence)\n",
    "print(type(words), len(words))\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e771ddfb-bcbe-4fcf-90d2-8c9dc71168a5",
   "metadata": {},
   "source": [
    "### 여러 문장들에 대한 단어 토큰화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e15c2324-c38f-4b81-aa8d-2987b43cfb12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize, sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "32c08c15-901f-437e-83ac-f12fffaddb82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_text(text):\n",
    "    sentences = sent_tokenize(text)\n",
    "    word_tokens = [word_tokenize(sentence) for sentence in sentences]\n",
    "    return word_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e769d8ab-57ab-4ad1-8f50-12b6aa91114c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'> 3\n",
      "[['The', 'Matrix', 'is', 'everywhere', 'its', 'all', 'around', 'us', ',', 'here', 'even', 'in', 'this', 'room', '.'], ['You', 'can', 'see', 'it', 'out', 'your', 'window', 'or', 'on', 'your', 'television', '.'], ['You', 'feel', 'it', 'when', 'you', 'go', 'to', 'work', ',', 'or', 'go', 'to', 'church', 'or', 'pay', 'your', 'texes', '.']]\n"
     ]
    }
   ],
   "source": [
    "word_tokens = tokenize_text(text_sample)\n",
    "print(type(word_tokens), len(word_tokens))\n",
    "print(word_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d6977ba-77dc-4b93-9f0f-a6b580909853",
   "metadata": {},
   "source": [
    "### n-gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7676f2a9-a55f-4765-a17f-1c6c62475d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4e5e82bb-de5a-45cd-ad97-34b66e41f275",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('The', 'Matrix', 'is'), ('Matrix', 'is', 'everywhere'), ('is', 'everywhere', 'its'), ('everywhere', 'its', 'all'), ('its', 'all', 'around'), ('all', 'around', 'us'), ('around', 'us', ','), ('us', ',', 'here'), (',', 'here', 'even'), ('here', 'even', 'in'), ('even', 'in', 'this'), ('in', 'this', 'room'), ('this', 'room', '.')]\n"
     ]
    }
   ],
   "source": [
    "sentence = \"The Matrix is everywhere its all around us, here even in this room.\"\n",
    "words = word_tokenize(sentence)\n",
    "\n",
    "all_ngrams = ngrams(words, 3)\n",
    "ngrams = [ngram for ngram in all_ngrams]\n",
    "print(ngrams)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd11c45a-3511-4428-baa1-bcdd3d4604fc",
   "metadata": {},
   "source": [
    "## Stopwords 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "637c8c7b-2490-4ff5-a2b1-62992f047332",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/hakchangs/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a4f60d20-0659-424d-9123-661436861f13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "영어 stop words 갯수: 179\n",
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his']\n"
     ]
    }
   ],
   "source": [
    "print('영어 stop words 갯수:', len(nltk.corpus.stopwords.words('english')))\n",
    "print(nltk.corpus.stopwords.words('english')[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "41d3cfcd-6786-4f55-874c-d4e45bddcc63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['matrix', 'everywhere', 'around', 'us', ',', 'even', 'room', '.'], ['see', 'window', 'television', '.'], ['feel', 'go', 'work', ',', 'go', 'church', 'pay', 'texes', '.']]\n"
     ]
    }
   ],
   "source": [
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "all_tokens = []\n",
    "\n",
    "for sentence in word_tokens:\n",
    "    filtered_words = []\n",
    "    for word in sentence:\n",
    "        word = word.lower()\n",
    "        if word not in stopwords:\n",
    "            filtered_words.append(word)\n",
    "    all_tokens.append(filtered_words)\n",
    "\n",
    "print(all_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca49eff-395a-49ac-bbc8-6932cf5f4fb2",
   "metadata": {},
   "source": [
    "## Stemming 과 Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4c7a56df-ae86-4e4b-b611-0e4b51761430",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import LancasterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a92ec99d-2323-4be7-9b7b-b101931eed34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "work word work\n",
      "amus amus amus\n",
      "happy happiest\n",
      "fant fanciest\n"
     ]
    }
   ],
   "source": [
    "stemmer = LancasterStemmer()\n",
    "\n",
    "print(stemmer.stem('working'), stemmer.stem('words'), stemmer.stem('worked'))\n",
    "print(stemmer.stem('amusing'), stemmer.stem('amuses'), stemmer.stem('amused'))\n",
    "print(stemmer.stem('happier'), stemmer.stem('happiest'))\n",
    "print(stemmer.stem('fancier'), stemmer.stem('fanciest'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0379283-bb0e-4d43-bb5d-079899b198b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
